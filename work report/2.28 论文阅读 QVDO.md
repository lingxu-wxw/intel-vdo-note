#### 2.28 论文阅读 QVDO

QVDO: QAT Accelerated Compression in Block Layer for File System Agnostic Storage

---

##### Abstract





---

##### Introduction

* 尽管hard drive的成本下降，这也补偿不了big data对带宽和存储的需求；因此data reduction technology会越来越重要
* 可以做data compression的level
  * 通常做在application layer；较高层做数据压缩有更多的信息（文件类型等，底层看都是block），可以有更好的性能，但这也存在限制
  * 较高层做压缩要求OS和file system是支持的，这减少了存储技术的可选范围；子系统也需要支持特殊的file system，但为了支持数据压缩去修改也是很困难的
  * 在较低层做数据压缩，比如block device layer，兼容file system specific compression就很容易
  * 比如read-only device的Cloop和CBD，read-write device的VDO和ZBD
* 数据压缩算法可以分为有损压缩和无损压缩
  * 尽管有损压缩发展很快，但无损压缩的应用field显然更大
  * 具有高压缩率的无损压缩通常会消耗可观的计算资源，为了缓解，hardware accelerator assisted compression成为选择，比如一些general propose hardware如GPU,FPGA
  * ASIC (Application Specific Integrated Circuit) 专用集成电路因为其效率和性能的优势受到关注，如Intel QuickAssist Technology和AHA Products Group of Comtech EF Data
    Corporation；ASIC效率更好的原因是它包含了software和general-purpose processor不能轻松实现的specialize logic

* QVDO是在VDO中集成QAT
  * QAT是一个用于计算密集型操作的硬件加速解决方案，可以提高云、网络、大数据和存储应用程序中的安全性和压缩性能
  * VDO是一种开源的块虚拟化技术，使用块设备作为备份存储，提供透明的压缩和重复数据删除层
  * QVDO，作为一个块层压缩解决方案，提供透明的文件系统不可知的压缩和高效的能源消耗比
    * 设置QAT offloading module，把compression offload到QAT上，用hardware zlib实现低CPU资源消耗，高吞吐和高压缩率
    * QVDO重构了整个压缩流程，包括使用异步机制，来配合hardware本身具备的异步特性
    * 实现同时考虑memory allocation、async function details、ensuring performance和safety；并且在压缩完成后，对write workflow也有优化，把packing procedure放到了multiple threads上执行，而不是single non-scalable thread

---

##### Background

##### 2.1 Block storage and compression

* block-level compression不受限于文件系统，它在写操作写入磁盘之前，或读操作从磁盘读取之后，使用压缩模块拦截IO path

* 这和upper-level compression有一点不同：variable output size和fixed block size和不匹配的，要做特殊处理；先前的研究主要是通过combine小的compressed block

  * VDO提供了block packing来固定压缩输出的大小，如图1，可以把来自不同输入数据块的几个压缩结果放到同一个output block中去
  * 尽管这样做对系统来说实现很方便，但碎片化是不能忽略的；如果数据的可压缩性不好，或者压缩算法的压缩率不高，都会效果不好（极端例子，4KB压缩到2.01KB，需要large padding，导致实际的压缩率又变回1）

  * 高压缩率算法在block-level compression中是不可替代的，尤其是在block packing的情境下

![1583132208467](img/1583132208467.png)

##### 2.2 Lossless compression algorithm

* block-level compression对上提供透明的无损压缩，用计算资源换磁盘空间；高压缩率低CPU占用的算法显然是最优解，但这对software algorithm来说做不到
* 我们比较两种无损压缩算法的性能： LZ4和zlib
  * LZ4属于LZ77家族，压缩解压缩的速度更快
  * zlib属于DEFLATE算法，是LZ77和Haffman编码的结合
  * VDO只提供了LZ4算法，我们实现了zlib来看看性能

![1583132525871](img/1583132525871.png)

* 如表1所示，zlib压缩率更高，但processing time特别长，并且CPU占用率为99%
  * 这会导致严重的race，并且影响同一个系统中的其他compute-bounded task
  * 因此在VDO中使用zlib是不能接受的

##### 2.3 Hardware-assisted compression

* 目前，各种硬件加速器的发展已经证明了它们有加速computed-bound workload的能力
  * ASIC比FPGA和GPU好主要是好在高性能和更高的性能消耗比
  * QAT的功能：通过硬件加速提供 高效的加密和压缩性能 服务

* 硬件压缩和软件压缩的不同
  * latency和throughput性能
  * 信息交互机制：
    * 软件没必要去做诸如把压缩分成几个task这样的交互优化，因为CPU就是用来做计算的
    * 硬件的系统交互和软件不太一样，通过DMA做memory allocation很高效且安全；且硬件有异步的function call来减少latency增加throughput
    * 异步的一些重要参数：accelerator instance number, next workflow module

---

##### Design

* QVDO的主要架构图

![1583134917430](img/1583134917430.png)

* 沿着IO path来看QVDO的执行过程

  * 上层传来一个bio request，VDO将其抽象成DataVIO
  * 在准备工作做好后，会执行read或write request，由VIO_read模块和VIO_write模块完成

  * 主要的修改在compression processing module
    * 选择压缩算法，与其他module交互比如packer module，保留消息通知机制
  * 新的模块，QAT offloading sub-module，把压缩逻辑offload到QAT
* write path的执行过程

  * 在deduplication module做完后才开始write path；如果data block没有做deduplication，它也会进入VIO_write module，然后先做compression processing module
  * 压缩模块中，会检查QVDO系统的压缩能力，注册callback function，选择合适的压缩算法；callback function会把compressed data发给packer module
  * 为了和QVDO底层交互，DataVIO会转化成另一个结构DataKVIO，然后task被若干个分开独立做压缩的CPU thread分摊
    * 每个thread都在做一些compute-bounded的task，比如compress和hash
    * DataKVIO被视为CPU queue中等待的一个work item，CPU queue是一个FIFO队列；之前的module会选择对应的CPU queue然后放进去
  * Compressing processing module会把item压进queue，选择压缩算法（包括QAT和software）
  * QAT offloading sub-module把request发给QAT硬件加速器，并获取返回
  * 当compressed data放进DataKVIO，会被发到packer module，发送是通过在compression processing module中注册的回调；packer会把一些small block data拼进一个4KB大小的data block
  * compressed data在被pack后，会理科被写入底层存储，或等待flush指令
* read path的执行过程
  * 当接收到read request，如果是data在compressed block里，request会发给底层存储；然后access 4KB block，把结果发给compressing processing module；完整的data block包含若干compressed fragment，可能只有一部分是实际要操作的部分
  * compressing processing module会选择对应的解压缩算法，然后把解压缩当做work item放进CPU queue中去
    * block head中有存mapping state，这里放了对应compressed fragment的position和length
  * 最后，compressed fragment的small piece会作为输入依次发给QAT offloading module，然后输出4KB data发给VIO_Read module

* QAT offloading sub-module的执行
  * 管理QAT compression instance，在workload中与其他module交互
  * 虽然QAT这种ACID hardware可以加速压缩的执行时间，但时间还是相对比较长的；不过，compression work item是在CPU queue中wait然后等待polling的，直到上一个work完成才会handle下一个
  * 这里的wait是不高效的，并没有完全发挥出QAT的性能，因此我们在这里做了async mechanism的优化，把执行过程分为两个部分：sending 和 receiving
    * 当sending过程一结束，work item就会被标记为finish，work queue中的下一个work item就会被poll到
    * receiving part会等待QAT hardware的回调，然后继续之前的workflow
    * context data会被保存并随着workflow一起发送

---

##### Implementation & Optimization

* 实现比较容易，使用QAT kernel API，只有2000行左右

##### 4.1 Compression processing module

