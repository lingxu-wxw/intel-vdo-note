#### 1.13 USDM deep dive

---

* adf_devmgr_pci_to_accel_dev的作用
* driver从哪里开始执行：register - search list - adf probe
* 每个repo能做什么
  * build system，build，编译
  * OSL，不同操作平台
  * CMI
* Linux内核源代码情景分析，8.4 PCI总线：pci bus相关的内容
* 执行的一个函数是adfdrv_init

----

#### USDM deep driver

* USDM的主要作用是分配内存，这段用来给CPM做DMA

  * 这段内存有一定的要求，不能被swap出去
  * 在内部会调用一些IOMMA的接口

  * 可以申请三种内存：small，large，huge page

* 代码结构

![image-20200113144148619](C:\Users\xinweiwa\AppData\Roaming\Typora\typora-user-images\image-20200113144148619.png)

* 暴露给用户态的四个API

```
int qarMemInit()
void* qaeMemAllocNUMA(...)
void qaeMemFreeNUMA(...)
uint64_t qatVirtToPhysNUMA(...)
```

* 时序图
  * lubusdm_drv.so是一个share lib
  * 打开USDM的一个fd，在后面去做IO control之类的
  * init ring的时候，会给ring分配ring buffer
  * qdm_iommu map

![image-20200113144445604](C:\Users\xinweiwa\AppData\Roaming\Typora\typora-user-images\image-20200113144445604.png)

* Internel API
  * alloc addr，内存初始化，数据整理
  * find slab，从已经被分配的里面找出空闲的内存
  * alloc slab，当没有可用内存的时候申请内存，真正和kernel交互申请内存的地方
  * add slab to hash，快速查找
  * store mmap range，把用户的虚拟地址做一个转换，找到物理地址
  * mem alloc，在slab的头中修改bitmap的控制信息，占用一块slab的user buffer
  * init stab and alloc，初始化
  * push slab，slab free后并不会马上delete，而是先从user list里删除，放进cachelist
  * pop slab，要用slab的时候会先找cachelist
  * free addr，如果slab里面没有可用了，就会从user list去掉，放进cachelist中
  * add slab to hash，实现slab到control的快速查找，12位
  * load addr，实现virt - phys的转换
  * store addr

![image-20200113145245428](C:\Users\xinweiwa\AppData\Roaming\Typora\typora-user-images\image-20200113145245428.png)

![image-20200113145256399](C:\Users\xinweiwa\AppData\Roaming\Typora\typora-user-images\image-20200113145256399.png)

* Internal Data Structure
* Slab Struture
  * block_ctrl_t，small slab的数据结构
  * allocation，含有多少个user buffer
  * 保证用户申请的内存在物理上是连续的
  * dev_mem_info_t,  pUserCacheHead
  * dev_mem_info_t,  pUserMemListHead
  * slab申请最小是2MB
  * 如果所有的datablock申请满了，会先去当前被使用的slab里去找，再去当前被释放的cache里去找，再不行就去找kernel去申请一个新的slab
  * 移到cache是只存一个指针的
  * free可以free一个slab的一部分data block，如果一个slab的所有data block都free了，就会移到cache里面去
  * 可以用huge memory防止黑客攻击；如果是small和large，都是用kmalloc申请的，这会收到kernel的管理，不会碎片化太严重

![image-20200113145506757](C:\Users\xinweiwa\AppData\Roaming\Typora\typora-user-images\image-20200113145506757.png)

![image-20200113150806071](C:\Users\xinweiwa\AppData\Roaming\Typora\typora-user-images\image-20200113150806071.png)

* Internel Flow
  * 用find slab找到user list里可用的slab

![image-20200113151102449](C:\Users\xinweiwa\AppData\Roaming\Typora\typora-user-images\image-20200113151102449.png)

* Page Table Walk

![image-20200113151406339](C:\Users\xinweiwa\AppData\Roaming\Typora\typora-user-images\image-20200113151406339.png)

* Page Table的算法开销
  * 空间上是 O(n)，时间上是O(1)
* USDM是自己管理内存的，因为要管理huge page，但huge page Linux是不管的，所以要有USDM
* Huge page
  * 默认关闭，要卸载掉当前正在运行的USDM driver，配置两个参数：max_huge_pages, max_huge_pages_per_process
  * 有两种huge page：2M，1G
  * 用mmap向kernel申请内存，而不是通过USDM driver，但USDM driver还是会做一些管理
  * page table从5级变成了4级
  * huge page的优点：直接可通过Linux管理，可以通过mem info来查看状态，可以通过debug信息看到现在有多少huge page再使用，可以减少被攻击的行为

* QAE提供了debug entry

